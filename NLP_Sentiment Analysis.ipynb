{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shravani703/PythonHomeworkUW/blob/main/NLP_Sentiment%20Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This a sentiment analysis assignment completed for my machine learning methods class of my graduate program in the winter quarter.**"
      ],
      "metadata": {
        "id": "QxgqkEyG7ABv"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XraaiIxdBM9X"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import string\n",
        "%matplotlib inline\n",
        "\n",
        "# sklearn specific imports \n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from gensim.models import Word2Vec\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5L5KWMjGB52D"
      },
      "source": [
        "### Part 0: Load and Clean Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrMCzZc9BlRf",
        "outputId": "a4aaf530-08d1-4898-fa0c-a5746f817750",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        }
      },
      "source": [
        "products = pd.read_csv('products.csv')\n",
        "products = products.iloc[0:5000] # For the sake of computation, we will only look at 5000 reviews\n",
        "print('Number of reviews:', len(products))\n",
        "print('Dataframe Columns', products.columns)\n",
        "# Let's look at a specific product\n",
        "print('Name:', products.iloc[0]['name'])\n",
        "print('Review:', products.iloc[0]['review'])\n",
        "print('Rating:', products.iloc[0]['rating'])\n",
        "\n",
        "# REMOVE products with review equal to 3\n",
        "products = products[products['rating'] != 3]\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    if type(text) != str:\n",
        "        return ''\n",
        "    return text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "products['review'] = products['review'].apply(remove_punctuation)\n",
        "len(products)\n",
        "products['sentiment'] = products['rating'].apply(lambda rating : +1 if rating > 3 else -1)\n",
        "products.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of reviews: 5000\n",
            "Dataframe Columns Index(['name', 'review', 'rating'], dtype='object')\n",
            "Name: Stop Pacifier Sucking without tears with Thumbuddy To Love's Binky Fairy Puppet and Adorable Book\n",
            "Review: All of my kids have cried non-stop when I tried to ween them off their pacifier, until I found Thumbuddy To Love's Binky Fairy Puppet.  It is an easy way to work with your kids to allow them to understand where their pacifier is going and help them part from it.This is a must buy book, and a great gift for expecting parents!!  You will save them soo many headaches.Thanks for this book!  You all rock!!\n",
            "Rating: 5\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                name  \\\n",
              "0  Stop Pacifier Sucking without tears with Thumb...   \n",
              "1    Nature's Lullabies Second Year Sticker Calendar   \n",
              "2    Nature's Lullabies Second Year Sticker Calendar   \n",
              "3    Nature's Lullabies Second Year Sticker Calendar   \n",
              "4                        Lamaze Peekaboo, I Love You   \n",
              "\n",
              "                                              review  rating  sentiment  \n",
              "0  All of my kids have cried nonstop when I tried...       5          1  \n",
              "1  We wanted to get something to keep track of ou...       5          1  \n",
              "2  I only purchased a secondyear calendar for my ...       2         -1  \n",
              "3  My daughter had her 1st baby over a year ago S...       5          1  \n",
              "4  One of babys first and favorite books and it i...       4          1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9474419b-b388-497b-82b2-be36646b8fe1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>review</th>\n",
              "      <th>rating</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
              "      <td>All of my kids have cried nonstop when I tried...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
              "      <td>We wanted to get something to keep track of ou...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
              "      <td>I only purchased a secondyear calendar for my ...</td>\n",
              "      <td>2</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
              "      <td>My daughter had her 1st baby over a year ago S...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Lamaze Peekaboo, I Love You</td>\n",
              "      <td>One of babys first and favorite books and it i...</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9474419b-b388-497b-82b2-be36646b8fe1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9474419b-b388-497b-82b2-be36646b8fe1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9474419b-b388-497b-82b2-be36646b8fe1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDpt1RM-pss1",
        "outputId": "7f73e224-67d2-49c8-d2fa-8b6fbdd32df2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjFaReqb69PH"
      },
      "source": [
        "products_train, products_test = train_test_split(products, test_size = 0.2, random_state = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCIsieDzPdbh"
      },
      "source": [
        "### A majority classifier\n",
        "\n",
        "A reasonable first classifier is to figure out what the majority sentiment is in the training set and use that as a predictor on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LS9iTN2sQgk6",
        "outputId": "a7af56bf-7faf-43df-c1cf-52e8cb4258c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# find the majority class (positive or negative) in the training set\n",
        "majority_sentiment = products_train['sentiment'].mode()[0]\n",
        "\n",
        "# predict how well this will do on the test set\n",
        "products_test['predicted_sentiment'] = majority_sentiment\n",
        "accuracy = (products_test['sentiment'] == products_test['predicted_sentiment']).mean()\n",
        "print('Accuracy:', accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.586\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IAQ6ft6RAJ-"
      },
      "source": [
        "### Featurizing sentences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pUfC3He5Lmg"
      },
      "source": [
        "Now we will use a ``CountVectorizer`` to turn our reviews, which our sentences, into features. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "It4D_H3i5K5o",
        "outputId": "082d7d75-3b73-496b-d74d-37f3bdf378f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "count_vectorizer = CountVectorizer(lowercase=True, token_pattern=u\"(?u)\\\\b\\\\w+\\\\b\", stop_words='english')\n",
        "X_train = count_vectorizer.fit_transform(products_train['review'])\n",
        "y_train = products_train['sentiment']\n",
        "\n",
        "words = count_vectorizer.get_feature_names_out()\n",
        "print(words) # show the vocabulary that it builds from the reviews in the training set\n",
        "\n",
        "# The two numbers printed out should match\n",
        "print('vocab in count_vectorizer:', len(count_vectorizer.get_feature_names_out()), 'dimension of X', X_train.shape[1])\n",
        "\n",
        "# We \"trained\" our count-vectorizer on the train set, now we run it on the test-set\n",
        "X_test = count_vectorizer.transform(products_test['review'])\n",
        "y_test = products_test['sentiment']\n",
        "\n",
        "# Finally we build a tokenizer\n",
        "tokenizer = count_vectorizer.build_analyzer() # We will use this later to tokenize our sentences"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['0' '001' '01' ... 'zoo' 'zookeepers' 'zoos']\n",
            "vocab in count_vectorizer: 14802 dimension of X 14802\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count_vectorizer.get_feature_names_out"
      ],
      "metadata": {
        "id": "ZaGoWqf3oPgX",
        "outputId": "902f75fd-5212-4af8-8f85-94a4ab5e9e8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method CountVectorizer.get_feature_names_out of CountVectorizer(stop_words='english', token_pattern='(?u)\\\\b\\\\w+\\\\b')>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkfOFjI1YU1t"
      },
      "source": [
        "**Question:** Why does a train and test set matter in this case? What is something that you may learn on the training set that does not appear in the test set?\n",
        "\n",
        "*Your answer here*\n",
        "\n",
        "Training and testing set both are important in sentiment analysis because it helps in evaluating the prformance/accuracy of the problem. The model forms a good relationship between the input feature and output which helps in predicting the ouput on testing data set. Testing set may contain such words that training set might not contain, therefore evaluation of performance on testing set becomes crucial.\n",
        "\n",
        "Here, the CountVectorizer is fitted onto the training dataset only. The frequencies of the words are learned here, and then they are applied to the test set to estimate the performance of the algorithm."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnJTBPT8It5l"
      },
      "source": [
        "### Build a Logistic Regression Classifier on Bag of Words Features\n",
        "\n",
        "Now we build a logistic classifier on our resulting feature representation. The logistic regression classifier is effectively going to learn a feature per word in our list of words on the training set from above. The parameter $C = 1/\\lambda$ is the regularization parameter specified as the inverse of $\\lambda$. Setting $C=1e25$ is like setting $\\lambda = 0$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iQF2fB47jUQ"
      },
      "source": [
        "# Train a logisitic regression model on the training set\n",
        "lr = LogisticRegression()\n",
        "sentiment_model = lr.fit(X_train, y_train) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1mEbmW18z1i"
      },
      "source": [
        "Now we can use this model to make predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXyqdzbL84Ve",
        "outputId": "5a0aad45-0e59-4c86-fb08-ca5b97029485",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "sample_test_data = X_test[1:11]\n",
        "# use sentiment_model.predict_proba to get the predicted probabilities for these three exmaples\n",
        "predicted_prob = sentiment_model.predict_proba(sample_test_data)\n",
        "\n",
        "pred_prob = predicted_prob[:,1]\n",
        "pred = (pred_prob >= 0.5).astype(int) * 2-1\n",
        "print(pred)\n",
        "#print(predicted_prob[:3])\n",
        "#y_pred = lr.predict(X_test)\n",
        "#acc = accuracy_score(y_test, y_pred)\n",
        "#print(acc)\n",
        "print(y_test[1:11])\n",
        "accuracy = (pred == y_test[1:11]).mean()\n",
        "print(accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-1 -1  1  1 -1 -1 -1 -1  1  1]\n",
            "4767   -1\n",
            "3814   -1\n",
            "3499   -1\n",
            "2735    1\n",
            "3922    1\n",
            "2701   -1\n",
            "1179   -1\n",
            "932    -1\n",
            "792     1\n",
            "1852    1\n",
            "Name: sentiment, dtype: int64\n",
            "0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_HoaK7YZ3Ld"
      },
      "source": [
        "**Question:** For this set, check if the majority predicted probability matches the true label. What is your accuracy?\n",
        "\n",
        "Accuracy : 0.8\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7n4eeispLG5",
        "outputId": "690defb6-e7b9-420a-beab-55f5cff39edd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(list(zip(words[1500:1520],sentiment_model.coef_[0,1500:1520])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('bathsi', -0.01879155131918723), ('baththe', 0.08114320284308224), ('bathtime', 0.09278254596438429), ('bathtimeand', -9.306374813260803e-05), ('bathtub', 0.4713882990122745), ('bathtubs', 0.20648651945610857), ('bathtubthe', -0.012675606301970671), ('bathtubthis', 0.05923402067021712), ('batiste', -0.04019695452466787), ('batted', 0.04047100300667036), ('battered', 0.015435312115969279), ('batteries', -0.7777566448284221), ('batteries3', -0.0007042062391138165), ('batteriesnow', -0.00835076210828282), ('battery', -0.672336811637484), ('batterytake', -9.641504853212602e-06), ('batting', -0.012246095625858069), ('battle', -0.01637143240296546), ('bauer', -0.3547659435743857), ('baught', -0.05601071173644782)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRGs01nQm28Y",
        "outputId": "1427ab36-35c4-4dc6-a2e5-57fbc5c4822d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# get 5 largest indices\n",
        "coeff = sentiment_model.coef_[0]\n",
        "words = count_vectorizer.get_feature_names_out()\n",
        "\n",
        "large_coeff = np.argsort(coeff)[::-1][:5]\n",
        "print(large_coeff)\n",
        "\n",
        "small_coeff = np.argsort(coeff)[::1][:5]\n",
        "print(small_coeff)\n",
        "\n",
        "ltwords = [words[i] for i in large_coeff]\n",
        "stwords = [words[i] for i in small_coeff]\n",
        "print(ltwords)\n",
        "print(stwords)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7585 6190 7593 4379 1637]\n",
            "[ 3905 10767 12948  2950 14269]\n",
            "['love', 'highly', 'loves', 'easy', 'best']\n",
            "['disappointed', 'returned', 'terrible', 'concept', 'waste']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlVDjudaI2p9"
      },
      "source": [
        "### Assessing the Bag of words model\n",
        "\n",
        "We will now use the model to build a confusion matrix. A common tool that helps assess classification models is the confusion matrix.\n",
        "\n",
        "We've created a function that will plot a confusion matrix for you given a set of inputs which are the values that should appear within each cell.\n",
        "Recall that there are four values associated with a confusion matrix: true positive, true negative, false positive, and false negative which we will abberviate as TP, TN, FP, and FN, respecitvely. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s51wvFKPSn7X"
      },
      "source": [
        "def plot_confusion_matrix(tp, fp, fn, tn):\n",
        "    \"\"\"\n",
        "    Plots a confusion matrix using the values \n",
        "       tp - True Positive\n",
        "       fp - False Positive\n",
        "       fn - False Negative\n",
        "       tn - True Negative\n",
        "    \"\"\"\n",
        "    data = np.matrix([[tp, fp], [fn, tn]])\n",
        "    \n",
        "    sns.heatmap(data, annot=True, cmap='YlGnBu',\n",
        "                xticklabels=['Actual Pos.', 'Actual Neg.'], \n",
        "                yticklabels=['Pred. Pos.', 'Pred. Neg.'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8492CwFSpBx",
        "outputId": "f148a27f-7389-4ce9-94e6-09ce82c9734b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "tp = 0\n",
        "fp = 0\n",
        "tn = 0\n",
        "fn = 0\n",
        "i = 0\n",
        "pred = sentiment_model.predict(X_test)\n",
        "\n",
        "# Compute the number of true positives, false positives, true negatives, false negatives\n",
        "# on the test set. \n",
        "y_test1 = np.array(y_test)\n",
        "for y_true, y_pred in zip(y_test1, pred):\n",
        "    #print(y_true, y_pred)\n",
        "    if y_true == 1 and y_pred == 1:\n",
        "        tp += 1\n",
        "    elif y_true == -1 and y_pred == 1:\n",
        "        fp += 1\n",
        "    elif y_true == -1 and y_pred == -1:\n",
        "        tn += 1\n",
        "    elif y_true == 1 and y_pred == -1:\n",
        "        fn += 1\n",
        "plot_confusion_matrix(tp=tp, fp=fp, fn=fn, tn=tn)\n",
        "print(tp, fp, tn , fn)\n",
        "'''from sklearn.metrics import confusion_matrix\n",
        "conf_mat = confusion_matrix(y_test, pred)\n",
        "print(conf_mat)\n",
        "\n",
        "tp = conf_mat[1, 1]\n",
        "fp = conf_mat[0, 1]\n",
        "tn = conf_mat[0, 0]\n",
        "fn = conf_mat[1, 0]'''\n",
        "\n",
        "plot_confusion_matrix(tp=tp, fp=fp, tn=tn, fn=fn)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "322 89 497 92\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 3 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAD4CAYAAADSIzzWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAAj80lEQVR4nO3deZwU1bn/8c93BgQREBEkOIAgiwQ3NIBbJEqiicaIGo1LosSrYiLmasw1akyuel/qz3hNzMWdSASjAcUlGiSJKBjXgGyyiOhEUEAUjYgoCuI8vz/6DLYj9PQUXfScqeftq150na7uOl/GeTh9uhaZGc4557a+inJ3wDnnssoLsHPOlYkXYOecKxMvwM45VyZegJ1zrkyapb2DPe98yg+ziMS80zqVuwuuaH2U5FXbdju56N/Hj14fl2gf5RZTxtQLsHOu8ZCa/ofemDJ6AXYuQ5SBWceYMnoBdi5DYhodJhVTRi/AzmVITMUpqZgyegF2LkOkynJ3IXUxZfQC7FyGxDQ6TCqmjF6AncuQmIpTUjFl9ALsXIbEdIRAUjFl9ALsXIbENDpMKqaMXoCdy5CYilNSMWX0AuxchlREdIRAUjFl9ALsXIbENDpMKqaMXoCdy5CYilNSMWX0AuxchsRUnJKKKaMXYOcyJZ7ilFw8Gb0AO5chFRVN/1c+pozx9NQ5t8ViOkkhqZgyegF2LkNimh9NKqaMXoCdyxApyrsMNUhMGb0AO5chMY0Ok4opoxdg5zIkpvnRpGLKGE9PnXNbrKKiWdFLMSRVSpotaWJYHyNpsaQ5Yekf2iVppKRqSXMl7esZfQTsXKakMDo8D1gItM1ru9DM7quz3RFA77DsB9wS/iy5mDL6CNi5LFFF8Ut9byV1Ab4N3F7EnocCd1rOP4F2kjpvWZjNdSyejF6AncsQqaIBi4ZLmpG3DK/zdr8Dfg7U1Gm/KnwEv15Si9BWBSzN22ZZaMt0Ri/AzmWIpKIXMxtlZgPyllF573MUsNLMZtbZxSVAX2Ag0B64aOul29i3aDJ6AXYuQ0RF0Us9DgKOlrQEGA8MkXSXma0IH8HXAXcAg8L2y4Guea/vEtpKLqaMXoCdyxBVVBa9FGJml5hZFzPrDpwETDGzH9TOeSp3NsQxwPzwkoeB08KRAvsDq81sRdYz+lEQzmVJ+kOuuyV1BATMAX4U2icBRwLVwFrg9NR6EFFGL8DOZUkKp+ma2RPAE+HxkM1sY8CIku98UyLK6AXYuSyJ6DoJiUWU0Quwc1mShW99IsqYqKuSLi9xP5xzW4FVqOglVjFlTDoCrntcnHMuBo2g6KQuooyJCrCZ/aXUHXHObQURzY8mFlHGeqcgJF0rqa2k5pIel/S2pB9sjc4550pMDVhiFVHGYuaADzez94GjgCVAL+DCNDvlnEtJhYpfYhVRxmKmIGq3+TYwwcxWx3TLD+dcniz87kaUsZgCPFHSS8BHwI/DGSAfp9st51wqKuMpTolFlLHeKQgzuxg4EBhgZp8AH5K77qVzLjYRzY8mFlHGekfAkpoDPwAGh6mHfwC3ptwv51wKLKKP50nFlLGYKYhbgObAzWH91NB2Zlqdcs6lpBF88ZS6iDIWU4AHmtneeetTJL2QVoeccymKpzYlF1HGYgrwp5J6mtm/ACTtCnyabrecc6mI6ON5YhFlLKYAXwhMlfQquX9bdiHNa3k659IT0RECiUWUsWABDoecrSZ3y42dQvOicCsO51xsIhodJhZRxs0ehibpTGABcAO5q753N7O5Xnydi5hU/BKriDIWGgGfD+xuZm+Hed+7yd3zyDkXq4iulZtYRBkLdXW9mb0NYGavAi22Tpecc6kp8ehQUqWk2ZImhvUekqZJqpZ0j6RtQnuLsF4dnu/uGQsX4C6SRtYum1h3zkXGKlX0UqTzgIV5678GrjezXsAq4IzQfgawKrRfH7ZLRUwZC01B1L3iWbQXYW/drILHT9ifCoEk5r39Pqc/Ou9z24w8pB8HVe2AGXz86aeMmLKAF95es0X7rWrdkvHf7s92zSr5cMOnnDRxNss/XMelg3pybK8vgWBDTQ2/evYVJr/2zhbty+Wcc86VPPXUTEB06NCOhx4ayYQJjzJy5N3U1BidOu3IxIk30bLlNuXuanmUcN5TUhdyF+m6Crgg3KZ9CHBK2GQscDm5E7eGhscA9wE3SlK4kWVpRZRxsyNgMxtbaNnSYFvTBxtqOOLB6Qz807N8ddxz9NuxDcf16vS5bZ5/6z2GTJjGgD89wzNvrOJ/B/ct+v2/33dnHjlmwBfarz14N+a/s4Z9736G+e+s4drwnotWfcDQh2Yw4O5nuGP+Mq48sM+WBXQAzJ9fzRNPPM9TT41l3rwHqKmp4eqrb+e668Zy442XMm/eA3Tq1J7LLrup3F0tnwZcJ0HScEkz8pbhdd7td8DPgZqwviPwnpltCOvLgKrwuApYChCeXx22L72IMmbmppzvfpz7+2rRrAIJaur8m/THhW9sfDx16b8ZXNV+4/qNQ/oxsFM7KiXmvfPF0fPm9G3fmpMnzQbg+lmLGXfkPgDc98pbG7eZ+OpKfrz3LokyuS8yg9WrP6Rly5asX7+BNm1aIYmDD94XgCOOOJgbbxxX5l6WUQNO0zWzUcCoTT0n6ShgpZnNlHRISfpWKhFljOj7wi3TrAKeP+VAnjpxf15Z9SF//tdbm932rD27Me+d3PTDGbt3oWvrbdlv3LMM+tMz9Ni+FSfv1rmofTavEC+vWgvAy6vW0nwT/2NcPKgnr6/5KEEiV9cee/RiyJD9OPzw4fTvfzwtW7bgkkvOBIwHH5wCwIQJj/Lhhxn++y7dF1QHAUdLWgKMJ/ex/P+AdpJqB3ZdgOXh8XKga64LagZsD/y7tOGCiDKmUoDzh/XvTm0cR65tqIGBf3qWb94/ne5tt2VI1/ab3O6Xg3pS1boF5z/xIgDf2KUD3dpuy/OnHMi0Uw6kbYtm9NuxNQDTTj6Q5085kJ8N6EGXNi15/pTc+pl7dCmqT6d+eWcO3HkHRkxZUJqQGbd06ZtMnz6XSZNuZtase1m//hOuuOIWLrvsx1x55a307388rVq1JNM3FGjAx/NCzOwSM+tiZt2Bk4ApZvZ9YCpwfNhsGPBQePxwWCc8PyWV+V+IKmOiKQhJR5nZxAId3zis3/POp9L5S05oxdr1LHz3Q47t9SWmLH33c8+dvnsVx/b+EidMnMXaDbkpHwF/W7ySS555+Qvvtd+4Z4HcHPApfXfm23+e8bnnP6kx+uzQipdXraXPDq34JG/e47BuO3LBV3pwzuMLWLrGr29fCnfdNZH27benZ8+uAAwZMogZM17kiitGcOKJ3wLg1lvv5Y03Vpazm+XVLPUPvRcB4yVdCcwGRof20cAfJVUD75IraOmIKGPSng5M+Lqy6N52Wzq3yn3r3Xab3Ah24b8/+Nw23+regf/cpzsjHp/Pq6s/+4g6+bV3GNKtA+1b5v6t6rfDduy6/bZF7XfRqg/56b49APjpvj146d3cPvfs0IZfD+7LVdOqeW7Fe1sazwW9e3fjjTdW8u67q6mpqeG5516gZ88uvPLKawB88MFaRo9+kNNOO7rMPS0fU/FL0e9p9oSZHRUev2pmg8ysl5mdUHvmrJl9HNZ7hedfTSdhXBmT3pb+siSvK5fe7Vpx9Vd3QwgEc1a+z81zX+eOw/di5srV3DjnNX65Xy8qJG4YsjsAH3zyKYdOmMboBcvYo0MbHv3ufkDusLGfTHnxc0V6cy566iXGHdmfWd8/iLUbPuXER+YAcNVBfWgmcdHAnlw0sCdmMCiMpl1yxx9/OA8+OIXBg3+IJHbaqT1XX30ew4ZdyqJFSzCDr31tAGeccVy5u1o+EV0rN7GIMmpzUxSSCv5famYPFLODxjYF4TZv3mmd6t/INRJ9ElWZXc++v+jfx1dv+248lSxPTBkLjYC/E/7cidw94aaE9UOBZ4GiCrBzrhGJaHSYWEQZN1uAzex0AEmPAv3MbEVY7wyM2Sq9c86VVhYOPI0oYzFzwF1ri2/wFtAtpf4459JUGVF1SiqijMUU4Mcl/R2oPX3oROCx9LrknEtLTHcMTiqmjPUWYDM7V9KxwODQNMrMHky3W865VMQzOEwuoozFHoY2C1hjZo9JaiWpjZlt2aXCnHNbX0RfUCUWUcZ6/62QdBa5S6vdFpqqgD+n2CfnXFoiul1PYhFlLGYEPILcTTmnAZjZK5J2KvwS51yjFNEdgxOLKGMxBXidma2vvYBJuMqPn1zhXIQsoo/nScWUsZgC/A9JvwC2lXQYcA7wl3S75ZxLRUTFKbGIMhbzfeFFwNvAPOBsYBLwyzQ75ZxLSUTzo4lFlLHgCFhSJbDAzPoCv986XXLOpSaiQ7QSiyhjwQJsZp9KWiSpm5m9vrU65ZxLSSMY9aUuoozFzAHvACyQNB34sLbRzLJ7UVXnYpX+xcrLL6KMxRTgX6XeC+fcVhHTabpJxZRxswVYUkvgR0Avcl/Ajc67FbNzLkbxDA6Tiyhjoa6OBQaQK75HAL/ZKj1yzqWnREcISGopabqkFyQtkHRFaB8jabGkOWHpH9olaaSkaklzJe3rGQtPQfQzsz3DG48Gpheb3znXSJXuGNl1wBAz+0BSc+BpSX8Nz11oZvfV2f4IoHdY9gNuCX+WXkQZCxXgT2ofmNmGTN/K27mmokTFKdxuvfbOts3DUugM2aHAneF1/5TUTlLnOtcaL42IMhaagthb0vthWQPsVftY0vsNzOKcawSsUkUvkoZLmpG3DM9/L0mVkuYAK4HJZjYtPHVV+Ah+vaQWoa0KWJr38mWhLdMZC92SqLKhwZ1zjVwDPsma2ShgVIHnPwX6S2oHPChpD+AS4E1gm/Dai4D/2YIeN1xEGSP6vtA5t8UqVPxSJDN7D5gKfMvMVljOOuAOcldSBFgOdM17WZfQVnoRZfQC7FyWqAFLobeROoZRIZK2BQ4DXgo37UW5L42OAeaHlzwMnBaOFNgfWJ3K/C9ElbHYO2I455qAitINuToDY8P1YiqAe81soqQpkjqSK29zyJ1LALmLeB0JVANrgdNL1pM6YsroBdi5DClVcTKzucA+m2gfspntjdzNHVIXU0YvwM5lSBYOJ40poxdg5zIkotqUWEwZvQA7lyExFaekYsroBdi5DFEGjnuKKaMXYOcyJKbRYVIxZfQC7FyGVEY0OkwqpoxegJ3LkJhGh0nFlNELsHMZEtMhWknFlNELsHMZEtMXVEnFlNELsHMZEtHgMLGYMnoBdi5DSnidhEYrpoxegJ3LkNLdrafxiimjF2DnMiSmj+dJxZTRC7BzGRJTcUoqpoxegJ3LEMX0+TyhmDJ6AXYuQ2IaHSYVU0YvwM5lSExHCCQVU8aIuuqc21Klul+lpJaSpkt6QdICSVeE9h6SpkmqlnSPpG1Ce4uwXh2e7+4ZvQA7lylS8Us91gFDzGxvoD/wrXAjyl8D15tZL2AVcEbY/gxgVWi/PmyXipgyegF2LkNUUfxSSLgt+wdhtXlYDBgC3Bfax5K7azDA0LBOeP7rSumiDTFl9ALsXIY0ZHQoabikGXnL8M+/lyolzQFWApOBfwHvmdmGsMkyoCo8rgKWAoTnVwM7Zj2jfwnnXIY0ZNBpZqOAUQWe/xToL6kd8CDQd0v7VwoxZfQC7FyGpHGEgJm9J2kqcADQTlKzMALsAiwPmy0HugLLJDUDtgf+XfrexJXRpyCcy5BSfUElqWMYFSJpW+AwYCEwFTg+bDYMeCg8fjisE56fYmZW0nAb+xZPxtRHwHNP2yntXbgS2bbbZeXugivSR6+PS/S6Ep4k1hkYK6mS3EDuXjObKOlFYLykK4HZwOiw/Wjgj5KqgXeBk0rWkzpiyuhTEM5lSKmKk5nNBfbZRPurwKBNtH8MnFCavRcWU0YvwM5lSIVS+dTfqMSU0QuwcxnSLKLrJCQVU0YvwM5lSEyjw6RiyugF2LkMiehKjYnFlNELsHMZkoXjTmPK6AXYuQyJaXSYVEwZvQA7lyGKaH40qZgyegF2LkNiOkIgqZgyegF2LkNiOkIgqZgyegF2LkNimh9NKqaMXoCdy5CYjhBIKqaMXoCdy5CYRodJxZTRC7BzGRLT/GhSMWX0AuxchsR0hEBSMWX0AuxchsQ0OkwqpoxegJ3LkJjmR5OKKaMXYOcyJKbilFRMGb0AO5chMR2ilVRMGWPqq3NuCzWrsKKXQiR1lTRV0ouSFkg6L7RfLmm5pDlhOTLvNZdIqpa0SNI3PaOPgJ3LlBKOuDYAPzOzWZLaADMlTQ7PXW9m1+VvLKkfuZtU7g7sDDwmqY+ZfVq6LuXElNFHwM5lSIWKXwoxsxVmNis8XkPudu1VBV4yFBhvZuvMbDFQzSZubFkKMWX0AuxchkjWgEXDJc3IW4Zv+j3Vndzdg6eFpnMlzZX0B0k7hLYqYGney5ZRuJhlIqMXYOcypCGjQzMbZWYD8pZRdd9PUmvgfuB8M3sfuAXoCfQHVgC/2Zr5IK6MPgfsXIaUcsQlqTm5wnS3mT0AYGZv5T3/e2BiWF0OdM17eZfQVnIxZfQRsHMZUsIjBASMBhaa2W/z2jvnbXYsMD88fhg4SVILST2A3sD0koYLYsroI2DnMqSEJykcBJwKzJM0J7T9AjhZUn/AgCXA2QBmtkDSvcCL5I4uGJHGERAQV0YvwM5lSGWJ3sfMngY2VeomFXjNVcBVJerCZsWU0QuwcxkS04Vqkoopoxdg5zIkpuskJBVTxkRfwkn6wqEazrnGr1QnKTRmMWVMOgK+raS9cM5tFc0zcNxTTBkTFWAzm1nqjjjn0hfT/GhSMWWstwBL+gu5wy3yrQZmALeZ2cdpdMw5V3qN4WN32mLKWMxg/VXgA+D3YXkfWAP0CevOuUhUNmCJVUwZi5mCONDMBuat/0XS82Y2UNKCtDrmnCu9mEaHScWUsZgC3FpSNzN7HUBSN6B1eG59aj1zzpVc83pOv20KYspYTAH+GfC0pH+ROyukB3COpO2AsWl2zjlXWjGNDpOKKWO9BdjMJknqDfQNTYvyvnj7XVodc86VXkzFKamYMhZzFEQr4AJgFzM7S1JvSbuZ2cT6Xuuca1xiKk5JxZSxmCmIO4CZwAFhfTkwgc+ugemci0RlRMfIJhVTxmIOQ+tpZtcCnwCY2Vo2fYUg51wjV9GAJVYxZSxmBLxe0raEkzEk9QTWpdor51wqmjWGqpOymDIWU4AvA/4GdJV0N7mLFP8wzU4559IR08fzpGLKWMxREJMlzQL2Jzf1cJ6ZvZN6z5xzJRfTF1RJxZRxs4N1Sd1qF2A7YB4wF2gV2pxzkSnVpRoldZU0VdKLkhZIOi+0t5c0WdIr4c8dQrskjZRUHW7nvq9nLDwCfoTcvG9+Nw3oCOxE4ziV2jnXACUcHW4AfmZmsyS1AWZKmkxuevJxM7tG0sXAxcBFwBHkblLZG9iP3K3d9ytZb/LElHGzBdjM9sxfl9Q97OQbwNUJAznnyqhUp+ma2QpgRXi8RtJCoAoYChwSNhsLPEGubgwF7jQzA/4pqZ2kzuF9SiqmjPV+XxhOvBgD/JXc8cD9zOyGpKGcc+WTxiFaYXC2DzAN6JRXcN4EOoXHVcDSvJctC20lF1PGzY6AJe0BXArsDlwLnJHWbaQbu3NHXM2TT84EjIMP/go33Xwpx3/3AhYtWoIktt++NePvuZaqqk71vpdLZs2rd7Fhw6eYQY0ZHfr+cIve76ZrzuIHJwwG4K4JTzLi4t/Tvl1rZk+5ju3btsIMXliwhEOO+e8S9L7xaMjHc0nDgeF5TaPMbFSdbVoD9wPnm9n70mc7MDOTtv4hCTFlLPSPwAvkzn57ChgEXB8mmEdKGpl0h7GZPPk5nnxyJk/84w6mPz+eGTMW8OyzczjssAN4fsZ45s67n86dO/LT8/+33F1t8gZ+82La7zasQcV3xbzbOWBAn8+19ei6E6d+bzD9D/kZex1yAad+bzC7dO0IwHU3P0S7XqdRtfeZ9O1dxcX/eWwpI5RdpYpfzGyUmQ3IW+oWpubkCtPdZvZAaH5LUufwfGdgZWhfDnTNe3mX0JbpjIUK8H+QOwZ4Ormph7pLJsycsYCdd+5I+/ZtadlyG7785R6MueMhzv7RCbRsuQ0Ag/bbg3feea+8Hc2gwQd8maVzbuPfi8bw5oLRHH5I/6Je95Mzj6B68ZssXrqS15a+TfXiNznvzCN5970PuOH2vwKwdu16lry+kl49vpRigq2vQlb0Uohyw8DRwEIz+23eUw8Dw8LjYcBDee2nhSMF9gdWpzH/C3FlLPQlnF9qEthv/725665HWLJkOW3btmHu3Ffo0vXzUw0PPvA4hx12wGbewZWCAdP+9v8A+PNfp3PG+Tcz/rYL+P45/8fUp+dz2ve+xpiRI9h5r7Pqfa9dunZkxZurNq6/+dZ7G0fAtbpW7Ui/3brwX1fcWdIc5VbCIwQOAk4F5kmaE9p+AVwD3CvpDOA14HvhuUnAkUA1sBY4vWQ9qSOmjEnvilxQ/rzKrbddwfDhJ6axm63i0EMHctRRX+OYoefRrFkzdt65I5UVn31w+I/Tf0VFRQX/fdmPytjLpu9rR/+S2fOX0LdXFc9OuprnZ1fTbvvtuH/0hRu3qajM/ebdcu1wThx6EAAtWzbnr+N+SU2N8d77H7LrwHPq3dc22zTjmYlXM+mx2Tz9z4XpBCqTZiUqTmb2NJu/JszXN7G9ASNKs/fCYsqYSgEO8yijAIxF8ZwXuBnX/Pp8rvn1+QCcdOKFdO6cGy1deukNzJmziMcev52KioZ8p+oaavb8JQC8VL2c52dXM/RbA6mpMdrvNuwL2/7456P48c9zU3kr5t3Ocadfy3MzXt74/GtL3+aQr+6xcf1LndrxxNPzN67PePRaVry1ipOG53/qbBpUutFhoxVTRq8aRah+5XUAZs9+iQUL/sV/XTiMW26+h4cfmsqE+35D+/Zty9zDpq1D+zZ06thu4+N99uzBE88sYO1H67jmVz/YuN1x3y7uuP4bbv8rvXp0ZpeuHdmla0d69ei8ce73sfsuY7tWLTjgyF+UPEdjoAYssYopY6IRsKSjsnRB9pNOupB16z6hokKc/9MfUFXViZtuGk9NjXHcsT8FoEuXTjwy6aYy97Rp6tunCw/feTEAknhm2kJ+feOfeWr6Qu4ZdQHDTz2MConnZizigUem1ft+i5eu5E/3P8W8J3Ij3Lvve5LFS1fylb125aBBfVm3/hPeWXgHAPc/8hxnXXBreuG2sphGh0nFlFG5aYsGvki6wswuK2bbpjAFkRWtul1e7i64In30+rhEZWbWO48U/fu4b4dvR1TKPhNTxkQj4GKLr3OucSnDeRFbXUwZC50Jd1yhF+YdlOyci0RMl2pMKqaMhUbA3wl/7gQcCEwJ64cCzwJegJ2LTES1KbGYMhY6EeN0AEmPkrsAz4qw3hkYs1V655wrqZhGh0nFlLGYOeCudU6newvwC7I7F6GIalNiMWUspgA/LunvwLiwfiLwWHpdcs6lJaZDtJKKKWMx94Q7V9KxwODQNMrMHky3W865NGThzKuYMhZ7GNosYI2ZPSaplaQ2ZrYmzY4550ovpvnRpGLKWMwdMc4C7gNuC01VwJ9T7JNzLiUxnaabVEwZixkBjyB3QfZpAGb2iqSdUu2Vcy4VMZ2kkFRMGYspwOvMbH3tbTgkNSN3eVbnXGQaw6gvbTFlLKYA/0PSL4BtJR0GnAP8Jd1uOefSENMRAknFlLGYAnwRcCYwDzib3FXfb0+zU865dFRGVJySiiljwQIsqRJYYGZ9gd9vnS4559ISUW1KLKaMBY+CCLehXyTJz3xzrgmQil/qfy/9QdJKSfPz2i6XtFzSnLAcmffcJZKqJS2S9M10EsaVsZgpiB2ABZKmAx/WNprZ0UW81jnXiJR4dDgGuBGoe+fS683sus/tV+oHnATsDuwMPCapTxjklVRMGYspwL9qUHedc41WKU9SMLMnJXUvcvOhwHgzWwcsllRN7vDW50rXo5yYMm52CkJSS0nnAycAfYFnzOwftUuxAZxzjUdDTlKQNFzSjLxleJG7OVfS3PDxfYfQVgUszdtmWWgruZgyFpoDHgsMIHf0wxHAb4rsmHOukaqQFb2Y2SgzG5C3jCpiF7cAPYH+wArKUDdiylhoCqKfme0JIGk0MD3pTpxzjUPax8ia2Vuf7Uu/B2pv3rsc6Jq3aZfQVnIxZSw0Av4kb4cbGt5N51xjk/Z1EsING2odC9QePfAwcJKkFpJ6AL1JaVAXU8ZCI+C9Jb1fu09yZ8K9Hx6bmbVN1HvnXNmU8lKNksYBhwAdJC0DLgMOkdSf3OUKlpA7eQszWyDpXuBFYAMwIo0jICCujIluS98Qflv6ePht6eOR9Lb07657uOjfx/Ytjo7pnIaNYsqY6Lb0zrk4KarLlScTU0YvwM5liBRPcUoqpoxegJ3LlChnFRoonoxegJ3LEEVUnJKKKaMXYOcyJZ7ilFw8Gb0AO5chMc2PJhVTRi/AzmVITEcIJBVTRi/AzmVITPOjScWU0Quwc5kSz+gwuXgyegF2LkMU0x0rE4opoxdg5zIlnuKUXDwZvQA7lyExzY8mFVNGL8DOZYioLHcXUhdTRi/AzmVITPOjScWU0Quwc5kST3FKLp6MXoCdy5CYTlJIKqaMXoCdy5R4RofJxZPRC7BzGRLTdRKSiiljPD11zm0xUVH0Uu97SX+QtFLS/Ly29pImS3ol/LlDaJekkZKqJc2VtK9n9ALsXMaU9J7BY4Bv1Wm7GHjczHoDj4d1gCPI3SW4NzAcuGULQtQjnoxegJ3LEDXgv/qY2ZPAu3WahwJjw+OxwDF57Xdazj+BdnVu714yMWX0AuxchkhqyDJc0oy8ZXgRu+hkZivC4zeBTuFxFbA0b7tloa3kYsroX8I5lynFj7nMbBQwKumezMwkFX2L+NKJJ6MXYOcyZCscI/uWpM5mtiJ8/F4Z2pcDXfO26xLaSi6mjD4F4VyGNOTjeUIPA8PC42HAQ3ntp4UjBfYHVud9jC+pmDL6CNi5TCndmEvSOOAQoIOkZcBlwDXAvZLOAF4Dvhc2nwQcCVQDa4HTS9aRL4gno8zSnaIxFpVhDsgl0arb5eXugivSR6+PSzh8e7kBv4994jml7HPiyZh6AW6qJA0PE/iukfOflWusfA44uWIOV3GNg/+sXKPkBdg558rEC7BzzpWJF+DkfE4xHv6zco2SfwnnnHNl4iNg55wrEy/AzjlXJk2uAEs6RpJJ6lvEtudLarUF+/qhpBs30/62pDmSXpR0VtJ9NFWN6OdUI2mvvLb5kron3ZdzDdHkCjBwMvB0+LM+5wOJf7HrcY+Z9Sd3GuPVkjoV3jxzGsvPaRlwaUrv7VxBTaoAS2oNfBU4Azgpr71S0nVhdDNX0k8k/SewMzBV0tSw3Qd5rzle0pjw+DuSpkmaLemxhhRTM1sJ/AvYRdLXw3vMU+5WJy3C+18TRspzJV235X8TjVsj+zlNBHaXtNsm+nm4pOckzZI0IfQbSUdKeknSTOVuQTMx+d+Gy7ImVYDJXZH+b2b2MvBvSV8J7cOB7kB/M9sLuNvMRgJvAIea2aH1vO/TwP5mtg8wHvh5sR2StCuwK7mR1hjgRDPbk9yFkH4saUfgWGD30Lcri33viDWmn1MNcC3wi/xGSR2AXwLfMLN9gRnABZJaArcBR5jZV4CORezDuU1qagX4ZHK/eIQ/az/efgO4zcw2AJhZ3VuM1KcL8HdJ84ALgd2LeM2JkuYA44Czyf2iLg5FB3K3MhkMrAY+BkZLOo7cVZSausb0cwL4E7C/pB55bfsD/YBnws9xGLAL0Bd41cwWh+3GNbCPzm3UZC5HKak9MATYU7kr1FcCJunCBrxN/kHRLfMe3wD81swelnQIcHkR73WPmZ2b17+9N7lDsw2SBgFfB44Hzg05mqRG+HOq/Rn8Brgov6vAZDP73By1pP4N6KdzBTWlEfDxwB/NbBcz625mXYHFwMHAZOBsSc1gYxEAWAO0yXuPtyR9WVIFuWmBWtvz2ZXth5HMIqC7pF5h/VTgH2FecXszmwT8FNhkoW5CGuvPaQy5EXjtlMI/gYNqf16StpPUh9zPcde8IyVObOB+nNuoKRXgk4EH67TdH9pvB14H5kp6ATglPD8K+Fvtlzvkbi89EXgWyL+S/eXABEkzgXeSdM7MPiZ3geYJ4SNyDXArucIyUdJccnOYFwBIOlrS/yTZVyPXKH9OZrYeGAnsFNbfBn4IjAs/m+eAvmb2EXBO6M9Mcv84rAaQNEDS7Q3Zr8s2PxXZuQaS1NrMPpAk4CbgFTO7vtz9cvFpSiNg57aWs8IXcwvITXvcVt7uuFj5CNg558rER8DOOVcmXoCdc65MvAA751yZeAF2zrky8QLsnHNl8v8BQ/8otYT9ZCUAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtFk_vRd9wFh"
      },
      "source": [
        "\n",
        "Now that we have succesfully trained a model, we compare the accuracy of the `sentiment_model` to that of the baseline majority class classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mrhW-tBLxIu",
        "outputId": "309b6f04-6036-480a-eed4-f122a65952ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# use sklearns accuracy_score function to compute the accuracy of the model on the test set\n",
        "s1 = accuracy_score(products_test['sentiment'], products_test['predicted_sentiment'])\n",
        "s2 = accuracy_score(y_test, pred)\n",
        "print(s1)\n",
        "print(s2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.586\n",
            "0.819\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akfXBOStI6dJ"
      },
      "source": [
        "### Build a Classifier using word2vec features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SPfk5n_I51q",
        "outputId": "cd7493f4-6c66-4369-aef2-ab48346d5a19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import gensim.downloader as api\n",
        "model = api.load(\"glove-twitter-100\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 387.1/387.1MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUby_VyK-OtL"
      },
      "source": [
        "Now we will take each sentence and build a feature vector base on our Word2Vec model. \n",
        "\n",
        "For each sentence in the dataset, we will first split it into words (tokenize it) using the ``count_vectorizer.build_tokenizer()`` function. Then for each word, we will use word2vec to get a word embedding, and we will average these over the words in a review"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPTwlpVtYbJ9"
      },
      "source": [
        "# word2vec model\n",
        "def get_average_word2vec(sentence, tokenizer, word2vec):\n",
        "    tokens = tokenizer(sentence)\n",
        "    v  =0\n",
        "    total = 0\n",
        "    for word in tokens:\n",
        "        if word in word2vec.vocab:\n",
        "            total += 1\n",
        "            vec = word2vec.word_vec(word) # TODO: get the word_vec from the word2vec model as in Problem 4\n",
        "            v += vec/np.linalg.norm(vec) \n",
        "    if total>0:\n",
        "        return v/total\n",
        "    return np.zeros(300)\n",
        "\n",
        "# The tokenizer we use was trained above\n",
        "X_train = np.array([get_average_word2vec(sentence, tokenizer, model) for sentence in products_train['review']])\n",
        "X_test = np.array([get_average_word2vec(sentence, tokenizer, model) for sentence in products_test['review']])\n",
        "\n",
        "# Train a logistic model \n",
        "sentiment_model_w2v = LogisticRegression()\n",
        "model = sentiment_model_w2v.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHURNj92EG8i"
      },
      "source": [
        "Now we can train the model and assess it's accuracy on the\n",
        "test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClN78yx714hs",
        "outputId": "013abc40-cd7d-4e24-b1fa-5b99b44ca241",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# use sklearns accuracy_score function to compute the accuracy of the model on the test set\n",
        "pred1 = sentiment_model_w2v.predict(X_test)\n",
        "model_acc = accuracy_score(y_test, pred1)\n",
        "print(model_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.757\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYbS7i4-Mhf4"
      },
      "source": [
        "**Question:** Which model did better? Based on this, would you recommend one model over the other?\n",
        "\n",
        "*Your answer here*\n",
        "\n",
        "Looking at the accuracy of models for this problem statement, it is evident that the accuracy of bag of words is higher than baseline model. While logistic regression is a traditional method of performing sentiment analysis, word2vec model is a modern take on forming the relationship between words in a sentence stablishing the context of the problem. Word2vec requires more computational resources than logistic regression.\n",
        "\n",
        "Accuracy of logistic model is greater than word2vec in this case.\n",
        "\n",
        "**Remark**: There are many ways of taking sentences and featurizing them. Finding new effective ways of doing this is a hot topic of research and in the last few years after word2vec was introduced, several new models such as Glove, Bert, Elmo have been proposed (and buiilt at UW!). These models use Recurrent neural networks, and transformer architectures. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCiJuQnmEKsS"
      },
      "source": [
        "## Hyperparameter tuning to pick the best possible value of $\\lambda$.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Creating a hyper-parameter grid\n",
        "hyper_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
        "\n",
        "# Building logistic regression model\n",
        "sentiment_model1 = LogisticRegression()\n",
        "\n",
        "# 5-fold cross validation \n",
        "grid_search = GridSearchCV(sentiment_model1, hyper_grid, cv=5)\n",
        "\n",
        "# Fit to the training set\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Hyperparameters:\", grid_search.best_params_)\n",
        "print(\"Accuracy:\", grid_search.best_score_)"
      ],
      "metadata": {
        "id": "ccCI-hp5jJqQ",
        "outputId": "5ce493ab-d97a-4e41-e826-4cd83b6a97d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters: {'C': 10}\n",
            "Accuracy: 0.787\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    }
  ]
}